/**
 * AI Try-On Processor
 * Handles the actual AI processing for virtual try-on
 */

import {
  createSupabaseServerClient,
  createSupabaseAdminClient,
} from '@/lib/config/supabase';
import { GoogleGenAI } from '@google/genai';
import mime from 'mime';

export interface TryOnRequest {
  sessionId: string;
  userId: string;
  basePhotoUrl: string;
  clothingItems: Array<{
    id: string;
    imageUrl: string;
    category: string;
    name: string;
  }>;
}

export interface TryOnResult {
  success: boolean;
  resultUrl?: string;
  error?: string;
  processingTime?: number;
}

export class TryOnProcessor {
  // Access environment variables directly at runtime, not at build time
  private static get GEMINI_API_KEY() {
    return process.env.GEMINI_API_KEY;
  }
  private static readonly SUPABASE_URL = process.env.NEXT_PUBLIC_SUPABASE_URL;

  // Rate limiting: Track last API call time (disabled for development)
  // private static lastGeminiApiCall: number = 0;
  // private static readonly MIN_TIME_BETWEEN_CALLS = 60000; // 60 seconds minimum between calls

  // Global cooldown/disable windows (disabled for development)
  // private static cooldownUntilMs: number = 0; // short cooldown after 429
  // private static disabledUntilMs: number = 0; // longer disable if quota truly 0

  // Feature flag to fully disable Gemini without code changes
  private static get GEMINI_ENABLED() {
    const raw = (process.env.GEMINI_ENABLED ?? 'true').toLowerCase();
    return raw !== 'false' && raw !== '0' && raw !== 'off';
  }

  /**
   * Process a try-on session with AI
   */
  static async processTryOn(request: TryOnRequest): Promise<TryOnResult> {
    const startTime = Date.now();

    try {
      console.log('============================================');
      console.log('üîç TRY-ON PROCESSOR STARTED');
      console.log('Session ID:', request.sessionId);
      console.log('User ID:', request.userId);
      console.log('============================================');
      console.log('üìä Environment Check:');
      console.log(
        '  - GEMINI_API_KEY:',
        this.GEMINI_API_KEY ? 'SET ‚úÖ' : 'NOT SET ‚ùå'
      );
      console.log(
        '  - GEMINI_ENABLED:',
        this.GEMINI_ENABLED ? 'true ‚úÖ' : 'false ‚ùå'
      );
      console.log(
        '  - API Key Preview:',
        this.GEMINI_API_KEY
          ? this.GEMINI_API_KEY.substring(0, 10) + '...'
          : 'N/A'
      );
      console.log('============================================');

      if (
        !this.GEMINI_API_KEY ||
        this.GEMINI_API_KEY === 'placeholder-gemini-key'
      ) {
        console.log('‚ö†Ô∏è  USING SIMULATION MODE - API key not configured');
        console.log(
          '   Reason:',
          !this.GEMINI_API_KEY
            ? 'API key is undefined/null'
            : 'API key is placeholder value'
        );
        console.log('Starting AI simulation for session:', request.sessionId);
        // Fall back to simulation if no API key
        const result = await this.simulateAITryOn(request);
        console.log('Simulation result:', result);
        const processingTime = Date.now() - startTime;
        const finalResult = {
          success: true,
          resultUrl: result.resultUrl,
          processingTime,
        };
        console.log('Final TryOnProcessor result:', finalResult);
        return finalResult;
      }

      // Respect feature flag
      if (!this.GEMINI_ENABLED) {
        console.log('‚ö†Ô∏è  USING SIMULATION MODE - GEMINI_ENABLED is false');
        const result = await this.simulateAITryOn(request);
        const processingTime = Date.now() - startTime;
        return { success: true, resultUrl: result.resultUrl, processingTime };
      }

      // Cooldown/disable checks removed for development

      // Use real Gemini API for actual AI processing
      console.log('‚úÖ ALL CHECKS PASSED - Calling real Gemini API');
      console.log(
        'üì∏ Base Photo URL:',
        request.basePhotoUrl.substring(0, 60) + '...'
      );
      console.log('üëï Clothing Items:', request.clothingItems.length);
      const result = await this.callGeminiAPI(
        request.basePhotoUrl,
        request.clothingItems.map((item) => item.imageUrl),
        request.userId
      );

      const processingTime = Date.now() - startTime;

      return {
        success: true,
        resultUrl: result,
        processingTime,
      };
    } catch (error) {
      console.error('Try-on processing error:', error);
      // Fall back to simulation on error
      console.log('Falling back to simulation due to error');
      const result = await this.simulateAITryOn(request);
      const processingTime = Date.now() - startTime;
      return {
        success: true,
        resultUrl: result.resultUrl,
        processingTime,
      };
    }
  }

  /**
   * Simulate AI try-on processing
   * In a real implementation, this would:
   * 1. Download the base photo and clothing images
   * 2. Send them to Gemini or another AI service
   * 3. Get back a generated image of the user wearing the clothing
   */
  private static async simulateAITryOn(
    request: TryOnRequest
  ): Promise<{ resultUrl: string }> {
    // Simulate processing time
    await new Promise((resolve) => setTimeout(resolve, 2000));

    // For demo purposes, return a reliable placeholder image
    // In production, this would be the actual AI-generated result
    const placeholderImages = [
      'https://images.unsplash.com/photo-1441986300917-64674bd600d8?w=500&h=600&fit=crop&crop=face&auto=format&q=80',
      'https://images.unsplash.com/photo-1507003211169-0a1dd7228f2d?w=500&h=600&fit=crop&crop=face&auto=format&q=80',
      'https://images.unsplash.com/photo-1494790108755-2616b612b786?w=500&h=600&fit=crop&crop=face&auto=format&q=80',
      'https://images.unsplash.com/photo-1472099645785-5658abf4ff4e?w=500&h=600&fit=crop&crop=face&auto=format&q=80',
    ];

    // Use a deterministic selection based on session ID to avoid random failures
    const sessionHash = request.sessionId.split('-').pop() || '0';
    const imageIndex = parseInt(sessionHash, 16) % placeholderImages.length;
    const resultUrl = placeholderImages[imageIndex];

    console.log('Simulation returning result URL:', resultUrl);

    // Validate the URL before returning
    if (!resultUrl || resultUrl.trim() === '') {
      console.error('Simulation generated empty or null URL!');
      const fallbackUrl =
        'https://images.unsplash.com/photo-1441986300917-64674bd600d8?w=500&h=600&fit=crop&crop=face&auto=format&q=80';
      console.log('Using fallback URL:', fallbackUrl);
      return { resultUrl: fallbackUrl };
    }

    return { resultUrl };
  }

  /**
   * Download image from URL and convert to base64
   */
  private static async downloadImageAsBase64(
    imageUrl: string
  ): Promise<string> {
    try {
      console.log('üì• Downloading image:', imageUrl.substring(0, 60) + '...');
      const response = await fetch(imageUrl);
      if (!response.ok) {
        throw new Error(`Failed to download image: ${response.statusText}`);
      }
      const arrayBuffer = await response.arrayBuffer();
      const base64 = Buffer.from(arrayBuffer).toString('base64');
      console.log('‚úÖ Image downloaded and converted to base64');
      return base64;
    } catch (error) {
      console.error('‚ùå Error downloading image:', error);
      throw error;
    }
  }

  /**
   * Real AI integration with Gemini API for virtual try-on
   * Using Google Generative AI SDK from AI Studio (streaming approach)
   */
  private static async callGeminiAPI(
    basePhoto: string,
    clothingItems: string[],
    userId: string
  ): Promise<string> {
    try {
      console.log('=== Gemini API Call Starting (Google AI Studio SDK) ===');
      console.log('Timestamp:', new Date().toISOString());
      console.log('Model: gemini-2.5-flash-image');
      console.log('Base photo:', basePhoto);
      console.log('Clothing items:', clothingItems);
      console.log('==============================');

      // Initialize Google AI client (like AI Studio)
      const ai = new GoogleGenAI({
        apiKey: this.GEMINI_API_KEY!,
      });

      // Download and convert images to base64
      console.log('üì• Downloading images from URLs...');
      const basePhotoBase64 = await this.downloadImageAsBase64(basePhoto);
      const clothingItemsBase64 = await Promise.all(
        clothingItems.map((url) => this.downloadImageAsBase64(url))
      );
      console.log('‚úÖ All images downloaded and converted');

      // Final attempt: Frame as editing task with strict reference preservation
      const prompt = `TASK: Photo editing - clothing replacement only.

INPUT IMAGES (${1 + clothingItemsBase64.length} total):
1. Reference photo (first image below): A person standing in front of a white door
2. Clothing items (next ${clothingItemsBase64.length} images): Individual garments to apply to the person

CRITICAL CONSTRAINTS:
- You must use the EXACT person, pose, background, and lighting from the first reference photo
- ONLY the clothing should change - everything else must remain IDENTICAL
- The person's face, skin tone, body type, and hair must be EXACTLY as shown in the first photo
- The background (white door, floor) must be EXACTLY as shown in the first photo

INSTRUCTIONS:
Take the first reference photo and digitally replace ONLY the person's clothing with the items shown in images 2-${1 + clothingItemsBase64.length}. Think of this as Photoshop clothing swap - the base photo stays the same, only the outfit changes.

What to preserve from the first photo:
- Exact same person (face, features, skin tone, hair, body proportions)
- Exact same pose and position
- Exact same background (white door with panels)
- Exact same floor (beige/tan tile)
- Exact same lighting and shadows
- Exact same image framing and composition

What to change from the first photo:
- ONLY the clothing/outfit - replace with items from images 2-${1 + clothingItemsBase64.length}

Output: A photo-realistic image that looks like the person from the first photo changed their clothes. An observer should recognize this as the same person, same location, same everything - except the outfit.`;

      // Build the parts array with text prompt and images
      interface GeminiPart {
        text?: string;
        inlineData?: {
          mimeType: string;
          data: string;
        };
      }

      const parts: GeminiPart[] = [
        { text: prompt },
        // Add base photo
        {
          inlineData: {
            mimeType: 'image/jpeg',
            data: basePhotoBase64,
          },
        },
      ];

      // Add all clothing items
      clothingItemsBase64.forEach((clothingBase64) => {
        parts.push({
          inlineData: {
            mimeType: 'image/jpeg',
            data: clothingBase64,
          },
        });
      });

      console.log(
        `üì§ Sending ${parts.length} parts to Gemini (1 prompt + ${parts.length - 1} images)`
      );

      // Log the actual prompt being sent
      console.log(
        'üìù PROMPT PREVIEW (first 200 chars):',
        prompt.substring(0, 200) + '...'
      );

      // Configuration (same as AI Studio)
      const config = {
        responseModalities: ['IMAGE', 'TEXT'],
      };

      const model = 'gemini-2.5-flash-image';
      const contents = [
        {
          role: 'user' as const,
          parts: parts,
        },
      ];

      console.log('üì§ Calling Gemini API with streaming...');
      console.log('üîß Model:', model);
      console.log('üîß Config:', JSON.stringify(config));

      // Use streaming API (like AI Studio)
      const response = await ai.models.generateContentStream({
        model,
        config,
        contents,
      });

      console.log('‚úÖ Streaming started, processing chunks...');

      // Process streaming response
      for await (const chunk of response) {
        if (
          !chunk.candidates ||
          !chunk.candidates[0].content ||
          !chunk.candidates[0].content.parts
        ) {
          continue;
        }

        // Check for image in chunk
        if (chunk.candidates?.[0]?.content?.parts?.[0]?.inlineData) {
          console.log('‚úÖ Generated image found in stream!');
          const inlineData = chunk.candidates[0].content.parts[0].inlineData;
          const imageData = inlineData.data || '';
          const mimeType = inlineData.mimeType || 'image/png';

          console.log(
            `Image data length: ${imageData.length} characters, type: ${mimeType}`
          );

          const imageUrl = await this.uploadGeneratedImage(
            imageData,
            mimeType,
            userId
          );
          console.log('‚úÖ Image uploaded successfully');
          return imageUrl;
        } else if (chunk.text) {
          console.log('üìù Text chunk:', chunk.text);
        }
      }

      // No image found in stream
      console.log('‚ö†Ô∏è  No image found in stream, using fallback');
      return await this.createCompositeImage(basePhoto, clothingItems);
    } catch (error) {
      console.error('‚ùå Gemini API error:', error);

      // Handle rate limiting
      const errorMessage =
        error instanceof Error ? error.message : String(error);
      const hasRateLimit = errorMessage.includes('429');

      if (hasRateLimit) {
        console.warn('‚ö†Ô∏è  Rate limit hit, using composite image');
      }

      // Fall back to composite image on error
      return await this.createCompositeImage(basePhoto, clothingItems);
    }
  }

  /**
   * Upload generated image to Supabase Storage
   */
  private static async uploadGeneratedImage(
    base64Data: string,
    mimeType: string,
    userId: string
  ): Promise<string> {
    try {
      // Convert base64 to buffer
      const imageBuffer = Buffer.from(base64Data, 'base64');

      // Upload to Supabase Storage using ADMIN client (bypasses RLS)
      const supabaseAdmin = createSupabaseAdminClient();
      const fileName = `try-on-result-${Date.now()}.${mimeType.split('/')[1]}`;
      // Include userId folder for RLS policy compliance
      const filePath = `${userId}/${fileName}`;

      console.log('üîê Uploading generated image with admin client:', filePath);

      const { data, error } = await supabaseAdmin.storage
        .from('try-on-results')
        .upload(filePath, imageBuffer, {
          contentType: mimeType,
          upsert: false,
          cacheControl: '3600',
        });

      if (error) {
        console.error('‚ùå Upload error details:', error);
        throw new Error(`Failed to upload generated image: ${error.message}`);
      }

      console.log('‚úÖ Upload successful, data:', data);

      // Generate a signed URL that expires in 1 year (for long-term access)
      const { data: signedUrlData, error: signedUrlError } =
        await supabaseAdmin.storage
          .from('try-on-results')
          .createSignedUrl(filePath, 31536000); // 365 days in seconds

      if (signedUrlError || !signedUrlData) {
        console.error('‚ùå Error creating signed URL:', signedUrlError);
        // Fallback to public URL
        const {
          data: { publicUrl },
        } = supabaseAdmin.storage.from('try-on-results').getPublicUrl(filePath);
        console.log(
          '‚ö†Ô∏è  Using public URL (may not work if bucket is private):',
          publicUrl
        );
        return publicUrl;
      }

      console.log(
        '‚úÖ Generated signed URL for image:',
        signedUrlData.signedUrl
      );
      return signedUrlData.signedUrl;
    } catch (error) {
      console.error('Error uploading generated image:', error);
      throw error;
    }
  }

  /**
   * Create a composite image for virtual try-on (fallback)
   */
  private static async createCompositeImage(
    basePhoto: string,
    clothingItems: string[]
  ): Promise<string> {
    try {
      console.log('Creating composite image for virtual try-on...');

      // Return a more realistic placeholder that looks like a try-on result
      const tryOnPlaceholders = [
        'https://images.unsplash.com/photo-1441986300917-64674bd600d8?w=500&h=600&fit=crop&crop=face&auto=format&q=80',
        'https://images.unsplash.com/photo-1507003211169-0a1dd7228f2d?w=500&h=600&fit=crop&crop=face&auto=format&q=80',
        'https://images.unsplash.com/photo-1494790108755-2616b612b786?w=500&h=600&fit=crop&crop=face&auto=format&q=80',
        'https://images.unsplash.com/photo-1472099645785-5658abf4ff4e?w=500&h=600&fit=crop&crop=face&auto=format&q=80',
      ];

      // Select a random placeholder for now
      const randomIndex = Math.floor(Math.random() * tryOnPlaceholders.length);
      const selectedPlaceholder = tryOnPlaceholders[randomIndex];

      console.log('Using placeholder image:', selectedPlaceholder);
      return selectedPlaceholder;
    } catch (error) {
      console.error('Error creating composite image:', error);
      throw error;
    }
  }

  /**
   * Upload result to Supabase Storage
   */
  private static async uploadResultToStorage(
    resultImage: Buffer,
    sessionId: string,
    userId: string
  ): Promise<string> {
    const supabase = await createSupabaseServerClient();

    const fileName = `try-on-result-${sessionId}-${Date.now()}.jpg`;
    const filePath = `try-on-results/${userId}/${fileName}`;

    const { data, error } = await supabase.storage
      .from('try-on-results')
      .upload(filePath, resultImage, {
        contentType: 'image/jpeg',
        upsert: false,
      });

    if (error) {
      throw new Error(`Failed to upload result: ${error.message}`);
    }

    const {
      data: { publicUrl },
    } = supabase.storage.from('try-on-results').getPublicUrl(filePath);

    return publicUrl;
  }
}
